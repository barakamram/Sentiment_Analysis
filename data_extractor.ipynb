{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import pickle\n", "import tqdm\n", "import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from utils import get_label, extract_feature, get_first_letters\n", "from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class AudioExtractor:\n", "    \"\"\"A class that is used to featurize audio clips, and provide\n", "    them to the machine learning algorithms for training and testing\"\"\"\n", "    def __init__(self, audio_config=None, verbose=1, features_folder_name=\"features\", classification=True,\n", "                    emotions=['sad', 'neutral', 'happy'], balance=True):\n", "                    # emotions=['angry', 'sad', 'neutral', 'ps', 'happy'], balance=True):\n", "        \"\"\"\n", "        Params:\n", "            audio_config (dict): the dictionary that indicates what features to extract from the audio file,\n", "                default is {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}\n", "                (i.e mfcc, chroma and mel)\n", "            verbose (bool/int): verbosity level, 0 for silence, 1 for info, default is 1\n", "            features_folder_name (str): the folder to store output features extracted, default is \"features\".\n", "            classification (bool): whether it is a classification or regression, default is True (i.e classification)\n", "            emotions (list): list of emotions to be extracted, default is ['sad', 'neutral', 'happy']\n", "            balance (bool): whether to balance dataset (both training and testing), default is True\n", "        \"\"\"\n", "        self.audio_config = audio_config if audio_config else {'mfcc': True, 'chroma': True, 'mel': True, 'contrast': False, 'tonnetz': False}\n", "        self.verbose = verbose\n", "        self.features_folder_name = features_folder_name\n", "        self.classification = classification\n", "        self.emotions = emotions\n", "        self.balance = balance\n", "        # input dimension\n", "        self.input_dimension = None\n", "    def _load_data(self, desc_files, partition, shuffle):\n", "        self.load_metadata_from_desc_file(desc_files, partition)\n", "        # balancing the datasets ( both training or testing )\n", "        if partition == \"train\" and self.balance:\n", "            self.balance_training_data()\n", "        elif partition == \"test\" and self.balance:\n", "            self.balance_testing_data()\n", "        else:\n", "            if self.balance:\n", "                raise TypeError(\"Invalid partition, must be either train/test\")\n", "        if shuffle:\n", "            self.shuffle_data_by_partition(partition)\n", "    def load_train_data(self, desc_files=[\"train_speech.csv\"], shuffle=False):\n", "        \"\"\"Loads training data from the metadata files `desc_files`\"\"\"\n", "        self._load_data(desc_files, \"train\", shuffle)\n", "        \n", "    def load_test_data(self, desc_files=[\"test_speech.csv\"], shuffle=False):\n", "        \"\"\"Loads testing data from the metadata files `desc_files`\"\"\"\n", "        self._load_data(desc_files, \"test\", shuffle)\n", "    def shuffle_data_by_partition(self, partition):\n", "        if partition == \"train\":\n", "            self.train_audio_paths, self.train_emotions, self.train_features = shuffle_data(self.train_audio_paths,\n", "            self.train_emotions, self.train_features)\n", "        elif partition == \"test\":\n", "            self.test_audio_paths, self.test_emotions, self.test_features = shuffle_data(self.test_audio_paths,\n", "            self.test_emotions, self.test_features)\n", "        else:\n", "            raise TypeError(\"Invalid partition, must be either train/test\")\n", "    def load_metadata_from_desc_file(self, desc_files, partition):\n", "        \"\"\"Read metadata from a CSV file & Extract and loads features of audio files\n", "        Params:\n", "            desc_files (list): list of description files (csv files) to read from\n", "            partition (str): whether is \"train\" or \"test\"\n", "        \"\"\"\n", "        # empty dataframe\n", "        df = pd.DataFrame({'path': [], 'emotion': []})\n", "        for desc_file in desc_files:\n", "            # concat dataframes\n", "            df = pd.concat((df, pd.read_csv(desc_file)), sort=False)\n", "        if self.verbose:\n", "            print(\"[*] Loading audio file paths and its corresponding labels...\")\n", "        # get columns\n", "        audio_paths, emotions = list(df['path']), list(df['emotion'])\n", "        # if not classification, convert emotions to numbers\n", "        if not self.classification:\n", "            # so naive and need to be implemented\n", "            # in a better way\n", "            if len(self.emotions) == 3:\n", "                self.categories = {'sad': 1, 'neutral': 2, 'happy': 3}\n", "            elif len(self.emotions) == 5:\n", "                self.categories = {'angry': 1, 'sad': 2, 'neutral': 3, 'ps': 4, 'happy': 5, 'exited': 6}\n", "            else:\n", "                raise TypeError(\"Regression is only for either ['sad', 'neutral', 'happy'] or ['angry', 'sad', 'neutral', 'ps', 'happy']\")\n", "            emotions = [ self.categories[e] for e in emotions ]\n", "        # make features folder if does not exist\n", "        if not os.path.isdir(self.features_folder_name):\n", "            os.mkdir(self.features_folder_name)\n", "        # get label for features\n", "        label = get_label(self.audio_config)\n", "        # construct features file name\n", "        n_samples = len(audio_paths)\n", "        first_letters = get_first_letters(self.emotions)\n", "        name = os.path.join(self.features_folder_name, f\"{partition}_{label}_{first_letters}_{n_samples}.npy\")\n", "        if os.path.isfile(name):\n", "            # if file already exists, just load then\n", "            if self.verbose:\n", "                print(\"[+] Feature file already exists, loading...\")\n", "            features = np.load(name)\n", "        else:\n", "            # file does not exist, extract those features and dump them into the file\n", "            features = []\n", "            append = features.append\n", "            for audio_file in tqdm.tqdm(audio_paths, f\"Extracting features for {partition}\"):\n", "                feature = extract_feature(audio_file, **self.audio_config)\n", "                if self.input_dimension is None:\n", "                    self.input_dimension = feature.shape[0]\n", "                append(feature)\n", "            # convert to numpy array\n", "            features = np.array(features)\n", "            # save it\n", "            np.save(name, features)\n", "        if partition == \"train\":\n", "            try:\n", "                self.train_audio_paths\n", "            except AttributeError:\n", "                self.train_audio_paths = audio_paths\n", "                self.train_emotions = emotions\n", "                self.train_features = features\n", "            else:\n", "                if self.verbose:\n", "                    print(\"[*] Adding additional training samples\")\n", "                self.train_audio_paths += audio_paths\n", "                self.train_emotions += emotions\n", "                self.train_features = np.vstack((self.train_features, features))\n", "        elif partition == \"test\":\n", "            try:\n", "                self.test_audio_paths\n", "            except AttributeError:\n", "                self.test_audio_paths = audio_paths\n", "                self.test_emotions = emotions\n", "                self.test_features = features\n", "            else:\n", "                if self.verbose:\n", "                    print(\"[*] Adding additional testing samples\")\n", "                self.test_audio_paths += audio_paths\n", "                self.test_emotions += emotions\n", "                self.test_features = np.vstack((self.test_features, features))\n", "        else:\n", "            raise TypeError(\"Invalid partition, must be either train/test\")\n", "    def _balance_data(self, partition):\n", "        if partition == \"train\":\n", "            emotions = self.train_emotions\n", "            features = self.train_features\n", "            audio_paths = self.train_audio_paths\n", "        elif partition == \"test\":\n", "            emotions = self.test_emotions\n", "            features = self.test_features\n", "            audio_paths = self.test_audio_paths\n", "        else:\n", "            raise TypeError(\"Invalid partition, must be either train/test\")\n", "        \n", "        count = []\n", "        if self.classification:\n", "            for emotion in self.emotions:\n", "                count.append(len([ e for e in emotions if e == emotion]))\n", "        else:\n", "            # regression, take actual numbers, not label emotion\n", "            for emotion in self.categories.values():\n", "                count.append(len([ e for e in emotions if e == emotion]))\n", "        # get the minimum data samples to balance to\n", "        minimum = min(count)\n", "        if minimum == 0:\n", "            # won't balance, otherwise 0 samples will be loaded\n", "            print(\"[!] One class has 0 samples, setting balance to False\")\n", "            self.balance = False\n", "            return\n", "        if self.verbose:\n", "            print(\"[*] Balancing the dataset to the minimum value:\", minimum)\n", "        d = defaultdict(list)\n", "        if self.classification:\n", "            counter = {e: 0 for e in self.emotions }\n", "        else:\n", "            counter = { e: 0 for e in self.categories.values() }\n", "        for emotion, feature, audio_path in zip(emotions, features, audio_paths):\n", "            if counter[emotion] >= minimum:\n", "                # minimum value exceeded\n", "                continue\n", "            counter[emotion] += 1\n", "            d[emotion].append((feature, audio_path))\n", "        emotions, features, audio_paths = [], [], []\n", "        for emotion, features_audio_paths in d.items():\n", "            for feature, audio_path in features_audio_paths:\n", "                emotions.append(emotion)\n", "                features.append(feature)\n", "                audio_paths.append(audio_path)\n", "        \n", "        if partition == \"train\":\n", "            self.train_emotions = emotions\n", "            self.train_features = features\n", "            self.train_audio_paths = audio_paths\n", "        elif partition == \"test\":\n", "            self.test_emotions = emotions\n", "            self.test_features = features\n", "            self.test_audio_paths = audio_paths\n", "        else:\n", "            raise TypeError(\"Invalid partition, must be either train/test\")\n", "    def balance_training_data(self):\n", "        self._balance_data(\"train\")\n", "    def balance_testing_data(self):\n", "        self._balance_data(\"test\")\n", "        "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def shuffle_data(audio_paths, emotions, features):\n", "    \"\"\" Shuffle the data (called after making a complete pass through \n", "        training or validation data during the training process)\n", "    Params:\n", "        audio_paths (list): Paths to audio clips\n", "        emotions (list): Emotions in each audio clip\n", "        features (list): features audio clips\n", "    \"\"\"\n", "    p = np.random.permutation(len(audio_paths))\n", "    audio_paths = [audio_paths[i] for i in p] \n", "    emotions = [emotions[i] for i in p]\n", "    features = [features[i] for i in p]\n", "    return audio_paths, emotions, features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_data(train_desc_files, test_desc_files, audio_config=None, classification=True, shuffle=True,\n", "                balance=True, emotions=['sad', 'neutral', 'happy']):\n", "    # instantiate the class\n", "    audiogen = AudioExtractor(audio_config=audio_config, classification=classification, emotions=emotions,\n", "                                balance=balance, verbose=0)\n", "    # Loads training data\n", "    audiogen.load_train_data(train_desc_files, shuffle=shuffle)\n", "    # Loads testing data\n", "    audiogen.load_test_data(test_desc_files, shuffle=shuffle)\n", "    # X_train, X_test, y_train, y_test\n", "    return {\n", "        \"X_train\": np.array(audiogen.train_features),\n", "        \"X_test\": np.array(audiogen.test_features),\n", "        \"y_train\": np.array(audiogen.train_emotions),\n", "        \"y_test\": np.array(audiogen.test_emotions),\n", "        \"train_audio_paths\": audiogen.train_audio_paths,\n", "        \"test_audio_paths\": audiogen.test_audio_paths,\n", "        \"balance\": audiogen.balance,\n", "    }"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}