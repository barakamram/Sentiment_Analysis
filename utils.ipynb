{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import soundfile\n", "import librosa\n", "import numpy as np\n", "import pickle\n", "import os\n", "from convert_wavs import convert_audio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["AVAILABLE_EMOTIONS = {\n", "    \"neutral\",\n", "    \"calm\",\n", "    \"happy\",\n", "    \"sad\",\n", "    \"angry\",\n", "    \"exited\",\n", "    \"fear\",\n", "    \"disgust\",\n", "    \"ps\",  # pleasant surprised\n", "    \"boredom\"\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_label(audio_config):\n", "    \"\"\"Returns label corresponding to which features are to be extracted\n", "        e.g:\n", "    audio_config = {'mfcc': True, 'chroma': True, 'contrast': False, 'tonnetz': False, 'mel': False}\n", "    get_label(audio_config): 'mfcc-chroma'\n", "    \"\"\"\n", "    features = [\"mfcc\", \"chroma\", \"mel\", \"contrast\", \"tonnetz\"]\n", "    label = \"\"\n", "    for feature in features:\n", "        if audio_config[feature]:\n", "            label += f\"{feature}-\"\n", "    return label.rstrip(\"-\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_dropout_str(dropout, n_layers=3):\n", "    if isinstance(dropout, list):\n", "        return \"_\".join([ str(d) for d in dropout])\n", "    elif isinstance(dropout, float):\n", "        return \"_\".join([ str(dropout) for i in range(n_layers) ])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_first_letters(emotions):\n", "    return \"\".join(sorted([ e[0].upper() for e in emotions ]))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_feature(file_name, **kwargs):\n", "    \"\"\"\n", "    Extract feature from audio file `file_name`\n", "        Features supported:\n", "            - MFCC (mfcc)\n", "            - Chroma (chroma)\n", "            - MEL Spectrogram Frequency (mel)\n", "            - Contrast (contrast)\n", "            - Tonnetz (tonnetz)\n", "        e.g:\n", "        `features = extract_feature(path, mel=True, mfcc=True)`\n", "    \"\"\"\n", "    mfcc = kwargs.get(\"mfcc\")\n", "    chroma = kwargs.get(\"chroma\")\n", "    mel = kwargs.get(\"mel\")\n", "    contrast = kwargs.get(\"contrast\")\n", "    tonnetz = kwargs.get(\"tonnetz\")\n", "    try:\n", "        with soundfile.SoundFile(file_name) as sound_file:\n", "            pass\n", "    except RuntimeError:\n", "        # not properly formated, convert to 16000 sample rate & mono channel using ffmpeg\n", "        # get the basename\n", "        basename = os.path.basename(file_name)\n", "        dirname  = os.path.dirname(file_name)\n", "        name, ext = os.path.splitext(basename)\n", "        new_basename = f\"{name}_c.wav\"\n", "        new_filename = os.path.join(dirname, new_basename)\n", "        v = convert_audio(file_name, new_filename)\n", "        if v:\n", "            raise NotImplementedError(\"Converting the audio files failed, make sure `ffmpeg` is installed in your machine and added to PATH.\")\n", "    else:\n", "        new_filename = file_name\n", "    with soundfile.SoundFile(new_filename) as sound_file:\n", "        X = sound_file.read(dtype=\"float32\")\n", "        sample_rate = sound_file.samplerate\n", "        if chroma or contrast:\n", "            stft = np.abs(librosa.stft(X))\n", "        result = np.array([])\n", "        if mfcc:\n", "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n", "            result = np.hstack((result, mfccs))\n", "        if chroma:\n", "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n", "            result = np.hstack((result, chroma))\n", "        if mel:\n", "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n", "            result = np.hstack((result, mel))\n", "        if contrast:\n", "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n", "            result = np.hstack((result, contrast))\n", "        if tonnetz:\n", "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n", "            result = np.hstack((result, tonnetz))\n", "    return result"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_best_estimators(classification):\n", "    \"\"\"\n", "    Loads the estimators that are pickled in `grid` folder\n", "    Note that if you want to use different or more estimators,\n", "    you can fine tune the parameters in `grid_search.py` script\n", "    and run it again ( may take hours )\n", "    \"\"\"\n", "    if classification:\n", "        return pickle.load(open(\"grid/best_classifiers.pickle\", \"rb\"))\n", "    else:\n", "        return pickle.load(open(\"grid/best_regressors.pickle\", \"rb\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_audio_config(features_list):\n", "    \"\"\"\n", "    Converts a list of features into a dictionary understandable by\n", "    `data_extractor.AudioExtractor` class\n", "    \"\"\"\n", "    audio_config = {'mfcc': False, 'chroma': False, 'mel': False, 'contrast': False, 'tonnetz': False}\n", "    for feature in features_list:\n", "        if feature not in audio_config:\n", "            raise TypeError(f\"Feature passed: {feature} is not recognized.\")\n", "        audio_config[feature] = True\n", "    return audio_config\n", "    "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}